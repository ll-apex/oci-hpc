# 概要

イメージ分類トレーニングの実装は、コンピュータ・ビジョンの「Hello World」です。トピックに関するブログ投稿は多数ありますが、その多くはライブラリAPI、基礎となるプリンシパル、またはその両方を適切に説明することなくソリューションを提示しています。PyTorchの[分類子のトレーニング](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)・ガイドは開始するのに最適な場所です。ただし、コードの詳細の一部については、フィールドに新しく追加された読者にはあまりにも疎外と説明されています。このワークショップでは、そのチュートリアルを基に、より明確な学習パスを容易にするためのコードの説明を1行ずつ説明しています。このガイドでは、CPUを使用したモデルのトレーニング方法を示し、GPUリソースを利用するためのコードの更新方法について説明します。GPUインスタンスは無料層では使用できません。

推定ラボ時間: 60分

### テンソルについて

視覚表現は、コンピュータ・サイエンスの用語、データ構造およびアルゴリズムのコンテキスト化に役立ちます。テンサーの場合、[KDnuggetsは明確な説明を提供します](https://www.kdnuggets.com/2018/05/wtf-tensor.html)。定義をオンラインで検索する場合、テンソルと口語使用法の技術的な定義に混乱が生じる場合があります。技術的には、ベクトルは1次元のテンソルであり、行列は2次元のテンソルですが、多くの場合、テンソルはベクトルと行列の両方より大きいn次元のコンテナを指します。

![異なるサイズのテンサの視覚表現](images/tensor.png)

テンサーは人工知能アルゴリズムの構築の中心であり、コンピュート・リソースの最適化に関する議論を支えているため、この用語を理解することが重要です。NVIDIAの[テンソル・コアの管理](https://www.nvidia.com/en-us/data-center/tensor-cores/)は大幅な計算アクセラレーションが可能ですが、チューニングも可能であるため、モデルのトレーニングがGPUの使用に共通の懸念事項があります。幸いなことに、PyTorchには、TensorsをGPUに転送する責任を負うデータ・ローダーが含まれています。

### 目的

この演習で説明するトピック:

*   テンソル
*   DataLoaders
*   Convolutional Neural Networks(CNN)
*   損失関数とオプティマイザ
*   モデル・トレーニング
*   GPUアクセラレーション

### 前提条件

この演習では、次のことを前提としています。

*   Oracle Free Tierまたは有料クラウド・アカウント

## 確認

*   **著者** - Big Compute、シニア・ソリューション・アーキテクト、Justin Blau
*   **最終更新者/日付** - Justin Blau、Big Compute、2020年10月